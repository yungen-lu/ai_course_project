{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_missing_rate(df: pd.DataFrame):\n",
    "    missing = pd.DataFrame(df.isnull().sum()).reset_index()\n",
    "    missing.columns = ['Feature', 'Missing_Percent(%)']\n",
    "    missing['Missing_Percent(%)'] = missing['Missing_Percent(%)'].apply(lambda x: x / df.shape[0] * 100)\n",
    "    print(missing.loc[missing['Missing_Percent(%)']>0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data = pd.read_csv('./data/US_Accidents_March23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = [\n",
    "    'Source', 'Description', 'End_Lat', 'End_Lng',\n",
    "    'Zipcode', 'Timezone', 'Airport_Code', 'ID',\n",
    "    'Turning_Loop', 'Country', 'Precipitation(in)', 'Wind_Chill(F)'\n",
    "]\n",
    "ori_data.drop(drop_list,axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data.drop(ori_data[ori_data['Nautical_Twilight'].isnull()].index, inplace=True)\n",
    "ori_data.insert(loc=1, column='Twilight', value=[1]*len(ori_data))\n",
    "twilight_list = ['Sunrise_Sunset', 'Civil_Twilight','Nautical_Twilight', 'Astronomical_Twilight']\n",
    "#accumulate the twilight data\n",
    "for tl in twilight_list:\n",
    "    ori_data[tl] = ori_data[tl].apply(lambda x: 1 if x == 'Day' else 0)\n",
    "def set_day_or_night(x):\n",
    "    if x > 2:\n",
    "        return 1\n",
    "    elif x == 2:\n",
    "        if random.random() > 0.5:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "ori_data['Twilight'] = ori_data[twilight_list].sum(axis=1).apply(set_day_or_night)\n",
    "ori_data.drop(twilight_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data['Start_Time']=pd.to_datetime(ori_data['Start_Time'], format='ISO8601')\n",
    "ori_data['End_Time']=pd.to_datetime(ori_data['End_Time'], format='ISO8601')\n",
    "ori_data['elapsed_time'] = ori_data['End_Time'] - ori_data['Start_Time']\n",
    "ori_data['elapsed_time'] = ori_data['elapsed_time']/np.timedelta64(1,'m')\n",
    "\n",
    "ori_data['Minute']=ori_data['Hour']*60.0+ori_data[\"Start_Time\"].dt.minute\n",
    "ori_data['Hour'] = ori_data['Start_Time'].dt.hour\n",
    "ori_data['Month'] = ori_data['Start_Time'].dt.month\n",
    "\n",
    "nmonth = ori_data['Month']\n",
    "days_each_month = np.cumsum(np.array([0,31,28,31,30,31,30,31,31,30,31,30,31]))\n",
    "nday = [days_each_month[arg-1] for arg in nmonth.values]\n",
    "nday = nday + ori_data[\"Start_Time\"].dt.day.values\n",
    "ori_data['Day'] = nday\n",
    "\n",
    "ori_data['Weekday'] = ori_data['Start_Time'].dt.weekday\n",
    "# ori_data['Year'] = ori_data['Start_Time'].dt.year\n",
    "ori_data.drop('Start_Time', axis=1, inplace=True)\n",
    "ori_data.drop('End_Time', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary parentheses and 'city'\n",
    "ori_data['County'] = ori_data['County'].str.replace(r'\\(|\\)|city', '', case=False, regex=True)\n",
    "ori_data['County'] = ori_data['County'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data = ori_data.groupby('County').filter(lambda x: x['Temperature(F)'].notna().sum() >= 1 and x['Humidity(%)'].notna().sum() >= 1 and x['Visibility(mi)'].notna().sum() >= 1 and x['Wind_Speed(mph)'].notna().sum() >= 1 and x['Pressure(in)'].notna().sum() >= 1)\n",
    "\n",
    "ori_data.drop(ori_data[ori_data['Weather_Timestamp'].isna()].index, inplace=True)\n",
    "ori_data['Weather_Timestamp'] = pd.to_datetime(ori_data['Weather_Timestamp'])\n",
    "ori_data.sort_values('Weather_Timestamp', inplace=True)\n",
    "\n",
    "def fill_in_missing_value(missing_column: str, ori_data: pd.DataFrame):\n",
    "    # interpolate missing data and then fill in the rest(usaully start or end of the data)\n",
    "    ori_data[missing_column] = ori_data.groupby('County')[missing_column].transform(lambda x: x.interpolate(method='nearest').bfill().ffill())\n",
    "\n",
    "\n",
    "fill_in_missing_value('Temperature(F)', ori_data)\n",
    "fill_in_missing_value('Humidity(%)', ori_data)\n",
    "fill_in_missing_value('Visibility(mi)', ori_data)\n",
    "fill_in_missing_value('Wind_Speed(mph)', ori_data)\n",
    "fill_in_missing_value('Pressure(in)', ori_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'SW' 'CALM' 'W' 'S' 'NW' 'VAR' 'SE' 'E' 'NE']\n"
     ]
    }
   ],
   "source": [
    "wind_serie = ori_data['Wind_Direction']\n",
    "ori_data.drop(wind_serie[wind_serie.isnull()].index, inplace=True)\n",
    "ori_data['Wind_Direction'].replace(to_replace=['Calm'], value='CALM', inplace=True)\n",
    "ori_data['Wind_Direction'].replace(to_replace=['SSW', 'SSE', 'South'], value='S', inplace=True)\n",
    "ori_data['Wind_Direction'].replace(to_replace=['NNW', 'NNE', 'North'], value='N', inplace=True)\n",
    "ori_data['Wind_Direction'].replace(to_replace=['ESE', 'ENE', 'East'], value='E', inplace=True)\n",
    "ori_data['Wind_Direction'].replace(to_replace=['WSW', 'WNW', 'West'], value='W', inplace=True)\n",
    "ori_data['Wind_Direction'].replace(to_replace=['Variable'], value='VAR', inplace=True)\n",
    "print(ori_data['Wind_Direction'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data.drop(ori_data[ori_data['Weather_Condition'].isnull()].index, inplace=True)\n",
    "ori_data.drop(ori_data[ori_data['Weather_Condition'].str.contains('N/A', case=False)].index, inplace=True)\n",
    "ori_data.drop(ori_data[ori_data['Street'].isnull()].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data['Clear'] = np.where(ori_data['Weather_Condition'].str.contains('Clear|Fair', case=False, na=False), True, False)\n",
    "ori_data['Cloud'] = np.where(ori_data['Weather_Condition'].str.contains('Cloud|Overcast', case=False, na=False), True, False)\n",
    "ori_data['Rain'] = np.where(ori_data['Weather_Condition'].str.contains('Rain|Storm', case=False, na=False), True, False)\n",
    "ori_data['Heavy_Rain'] = np.where(ori_data['Weather_Condition'].str.contains('Heavy Rain|Thunderstorms|Heavy T-Storm', case=False, na=False), True, False)\n",
    "ori_data['Snow'] = np.where(ori_data['Weather_Condition'].str.contains('Snow|Hail|Sleet|Ice', case=False, na=False), True, False)\n",
    "ori_data['Heavy_Snow'] = np.where(ori_data['Weather_Condition'].str.contains('Heavy Snow|Heavy Ice|Heavy Sleet', case=False, na=False), True, False)\n",
    "ori_data['Fog'] = np.where(ori_data['Weather_Condition'].str.contains('Fog|Haze|Dust|Volcanic Ash|Smoke', case=False, na=False), True, False)\n",
    "ori_data['Windy'] = np.where(ori_data['Weather_Condition'].str.contains('Wind|Tornado', case=False, na=False), True, False)\n",
    "\n",
    "ori_data.drop('Weather_Condition', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Feature, Missing_Percent(%)]\n",
      "Index: []\n",
      "(7481003, 42)\n",
      "Index(['Severity', 'Twilight', 'Start_Lat', 'Start_Lng', 'Distance(mi)',\n",
      "       'Street', 'City', 'County', 'State', 'Weather_Timestamp',\n",
      "       'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)',\n",
      "       'Wind_Direction', 'Wind_Speed(mph)', 'Amenity', 'Bump', 'Crossing',\n",
      "       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n",
      "       'Stop', 'Traffic_Calming', 'Traffic_Signal', 'elapsed_time', 'Hour',\n",
      "       'Minute', 'Day', 'Month', 'Weekday', 'Clear', 'Cloud', 'Rain',\n",
      "       'Heavy_Rain', 'Snow', 'Heavy_Snow', 'Fog', 'Windy'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "show_missing_rate(ori_data)\n",
    "print(ori_data.shape)\n",
    "print(ori_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity 4\n",
      "Twilight 2\n",
      "Start_Lat 2359683\n",
      "Start_Lng 2409346\n",
      "Distance(mi) 21881\n",
      "Street 328636\n",
      "City 12266\n",
      "County 1746\n",
      "State 49\n",
      "Weather_Timestamp 933678\n",
      "Temperature(F) 859\n",
      "Humidity(%) 100\n",
      "Pressure(in) 1137\n",
      "Visibility(mi) 91\n",
      "Wind_Direction 10\n",
      "Wind_Speed(mph) 184\n",
      "Amenity 2\n",
      "Bump 2\n",
      "Crossing 2\n",
      "Give_Way 2\n",
      "Junction 2\n",
      "No_Exit 2\n",
      "Railway 2\n",
      "Roundabout 2\n",
      "Station 2\n",
      "Stop 2\n",
      "Traffic_Calming 2\n",
      "Traffic_Signal 2\n",
      "elapsed_time 73249\n",
      "Hour 24\n",
      "Minute 60\n",
      "Day 31\n",
      "Month 12\n",
      "Weekday 7\n",
      "Clear 2\n",
      "Cloud 2\n",
      "Rain 2\n",
      "Heavy_Rain 2\n",
      "Snow 2\n",
      "Heavy_Snow 2\n",
      "Fog 2\n",
      "Windy 2\n"
     ]
    }
   ],
   "source": [
    "for col in ori_data.columns:\n",
    "    print(col, ori_data[col].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data.to_csv('./data/v2-1.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-accident-predict-4yLnMnDS-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
