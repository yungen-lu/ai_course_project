{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import pandas as pd\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.metrics import classification_report\n",
            "from collections import Counter\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from imblearn.under_sampling import RandomUnderSampler\n",
            "import matplotlib.pyplot as plt\n",
            "rus = RandomUnderSampler(random_state=42)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "ori_data = pd.read_csv('./data/v2-4.csv', index_col=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "numerical_features = [\n",
            "    'Distance(mi)', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)',\n",
            "    'Wind_Speed(mph)', 'elapsed_time', 'Start_Lat', 'Start_Lng'\n",
            "]\n",
            "\n",
            "categorical_features = [f for f in list(ori_data.columns) if (f not in numerical_features)]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "X = ori_data.drop(['Severity'], axis=1)\n",
            "y = ori_data['Severity']"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Self-define score function"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "def custom_scoring(y_true, y_pred, verbose=False, equal_weighted_f1=False):\n",
            "    report = classification_report(y_true, y_pred, output_dict=True)\n",
            "    weighted_beta_f1 = 0\n",
            "    beta_weights = {\n",
            "        '1': 0.5,\n",
            "        '2': 1,\n",
            "        '3': 1,\n",
            "        '4': 2,\n",
            "    }\n",
            "    total_data_count = report['weighted avg']['support']\n",
            "    for cl in range(1, 5):\n",
            "        pr = report[str(cl)]['precision']\n",
            "        rc = report[str(cl)]['recall']\n",
            "        beta = beta_weights[str(cl)]\n",
            "        beta_f1 = ((1+beta**2)*pr*rc)/(pr*(beta**2) + rc)\n",
            "        if verbose: \n",
            "            print(f'beta f1 for level [{cl}]: {beta_f1}, pr: {pr}, rc: {rc}')\n",
            "\n",
            "        if not equal_weighted_f1:\n",
            "            support_proportion = report[str(cl)]['support'] / total_data_count\n",
            "            weighted_beta_f1 += beta_f1 * support_proportion\n",
            "        else:\n",
            "            weighted_beta_f1 += beta_f1*0.25\n",
            "\n",
            "    if verbose and equal_weighted_f1:\n",
            "        print(f\"macro avg for f1: {weighted_beta_f1}\")\n",
            "    return weighted_beta_f1"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### K-fold validation, evaluation function"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.model_selection import KFold\n",
            "from sklearn.metrics import precision_recall_curve, auc\n",
            "\n",
            "def cross_valid(X, y, estimator, cv=5, verbose=False, balance_cls=False, equal_weighted_f1=False):\n",
            "    total_f1 = 0\n",
            "    X.reset_index()\n",
            "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
            "    print('Validation data')\n",
            "    for i, (train_index, valid_index) in enumerate(kf.split(X)):\n",
            "        x_train, x_valid = X.iloc[train_index], X.iloc[valid_index]\n",
            "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
            "        \n",
            "        if balance_cls:\n",
            "            x_train, y_train = rus.fit_resample(x_train, y_train)\n",
            "            if verbose:\n",
            "                print('After under sampling:')\n",
            "                print(f'Length of training data: {len(x_train)}, and its distribution among each severity {Counter(y_train)}')\n",
            "\n",
            "        estimator.fit(x_train, y_train)\n",
            "        y_valid_pred = estimator.predict(x_valid)\n",
            "        beta_f1 = custom_scoring(y_valid, y_valid_pred, verbose=False, equal_weighted_f1=equal_weighted_f1)\n",
            "        print(f'Round {i} beta_f1: {beta_f1}')\n",
            "        total_f1 += beta_f1\n",
            "        \n",
            "    avg_betaf1 = total_f1 / cv\n",
            "    print(f'average beta f1-score after kfold: {avg_betaf1}')\n",
            "\n",
            "\n",
            "def test(estimator, x_test, y_test):\n",
            "    print('Testing data:')\n",
            "    y_test_pred = estimator.predict(x_test)\n",
            "    print(classification_report(y_test, y_test_pred))\n",
            "    beta_f1 = custom_scoring(y_test, y_test_pred, verbose=True)\n",
            "    print(f'beta f1-score: {beta_f1}')\n",
            "        \n",
            "def auc_pr(estimator, x_test, y_test):\n",
            "    y_scores = estimator.predict_proba(x_test)[:, 1]\n",
            "    precision = dict()\n",
            "    recall = dict()\n",
            "    n_classes = 4\n",
            "    for i in range(n_classes):\n",
            "        precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_scores[:, i])\n",
            "        plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
            "        \n",
            "    plt.xlabel(\"recall\")\n",
            "    plt.ylabel(\"precision\")\n",
            "    plt.legend(loc=\"best\")\n",
            "    plt.title(\"precision vs. recall curve\")\n",
            "    plt.show()\n",
            "        "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Model"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.multiclass import OneVsRestClassifier\n",
            "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\n",
            "from sklearn.tree import DecisionTreeClassifier\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "from sklearn.svm import LinearSVC"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "x_train_valid, x_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Direct Testing"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Decision Tree"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Testing data:\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           1       0.37      0.41      0.39     13140\n",
                  "           2       0.92      0.92      0.92   1191687\n",
                  "           3       0.71      0.72      0.71    252647\n",
                  "           4       0.34      0.36      0.35     38727\n",
                  "\n",
                  "    accuracy                           0.86   1496201\n",
                  "   macro avg       0.58      0.60      0.59   1496201\n",
                  "weighted avg       0.87      0.86      0.86   1496201\n",
                  "\n",
                  "beta f1 for level [1]: 0.37362990716922045, pr: 0.36617113105432625, rc: 0.4067732115677321\n",
                  "beta f1 for level [2]: 0.9191545171232114, pr: 0.9214750780129881, rc: 0.9168456146622393\n",
                  "beta f1 for level [3]: 0.7128401850929695, pr: 0.7089679040959667, rc: 0.7167549980803255\n",
                  "beta f1 for level [4]: 0.3518347919545524, pr: 0.33963242922780496, rc: 0.35502362692695016\n",
                  "beta f1-score: 0.8648413055855593\n"
               ]
            }
         ],
         "source": [
            "dt = DecisionTreeClassifier()\n",
            "dt.fit(x_train_valid, y_train_valid)\n",
            "test(dt, x_test, y_test)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Random Forest"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Testing data:\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           1       0.90      0.10      0.18     13140\n",
                  "           2       0.87      0.98      0.92   1191687\n",
                  "           3       0.82      0.48      0.61    252647\n",
                  "           4       0.91      0.01      0.03     38727\n",
                  "\n",
                  "    accuracy                           0.86   1496201\n",
                  "   macro avg       0.88      0.39      0.43   1496201\n",
                  "weighted avg       0.86      0.86      0.84   1496201\n",
                  "\n",
                  "beta f1 for level [1]: 0.33936170212765954, pr: 0.9017667844522969, rc: 0.09710806697108067\n",
                  "beta f1 for level [2]: 0.919490733990866, pr: 0.8667578447985749, rc: 0.9790557419859409\n",
                  "beta f1 for level [3]: 0.6069696931887656, pr: 0.8212481767597645, rc: 0.4813712412971458\n",
                  "beta f1 for level [4]: 0.018035917517023204, pr: 0.9121951219512195, rc: 0.014486017507165544\n",
                  "beta f1-score: 0.8382910559049715\n"
               ]
            }
         ],
         "source": [
            "rfc = RandomForestClassifier(n_estimators=50, max_depth=15)\n",
            "rfc.fit(x_train_valid, y_train_valid)\n",
            "test(rfc, x_test, y_test)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### OneVsRestClassifier with decision tree"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Testing data:\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           1       0.73      0.03      0.06     13140\n",
                  "           2       0.85      0.97      0.91   1191687\n",
                  "           3       0.74      0.40      0.52    252647\n",
                  "           4       0.74      0.01      0.01     38727\n",
                  "\n",
                  "    accuracy                           0.84   1496201\n",
                  "   macro avg       0.77      0.35      0.38   1496201\n",
                  "weighted avg       0.83      0.84      0.81   1496201\n",
                  "\n",
                  "beta f1 for level [1]: 0.1342412451361868, pr: 0.7263157894736842, rc: 0.031506849315068496\n",
                  "beta f1 for level [2]: 0.9087880746137068, pr: 0.8534444640962151, rc: 0.9718071943387819\n",
                  "beta f1 for level [3]: 0.520455376713993, pr: 0.7355233289475587, rc: 0.4027041682663954\n",
                  "beta f1 for level [4]: 0.008276812686389313, pr: 0.744927536231884, rc: 0.0066361969685232525\n",
                  "beta f1-score: 0.8131039144599154\n"
               ]
            }
         ],
         "source": [
            "clf = OneVsRestClassifier(DecisionTreeClassifier(max_depth=5)).fit(x_train_valid, y_train_valid)\n",
            "test(clf, x_test, y_test)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### OneVsRestClassifier with RandomForest"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Testing data:\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           1       0.84      0.15      0.25     13140\n",
                  "           2       0.87      0.98      0.92   1191687\n",
                  "           3       0.82      0.49      0.61    252647\n",
                  "           4       0.88      0.03      0.06     38727\n",
                  "\n",
                  "    accuracy                           0.86   1496201\n",
                  "   macro avg       0.85      0.41      0.46   1496201\n",
                  "weighted avg       0.86      0.86      0.84   1496201\n",
                  "\n",
                  "beta f1 for level [1]: 0.43670156139105754, pr: 0.837515950659294, rc: 0.14984779299847792\n",
                  "beta f1 for level [2]: 0.9205968645781485, pr: 0.86911590219355, rc: 0.9785606455386355\n",
                  "beta f1 for level [3]: 0.6142178027392642, pr: 0.8215675743772336, rc: 0.490439229438703\n",
                  "beta f1 for level [4]: 0.03617458559291106, pr: 0.8835027365129007, rc: 0.0291786092390322\n",
                  "beta f1-score: 0.8417203254510202\n"
               ]
            }
         ],
         "source": [
            "clf = OneVsRestClassifier(RandomForestClassifier(max_depth=15)).fit(x_train_valid, y_train_valid)\n",
            "test(clf, x_test, y_test)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## **KFold cross validation**"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Decision Tree"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Decision tree without balance dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Validation data\n",
                  "Round 0 beta_f1: 0.580193543669992\n",
                  "Round 1 beta_f1: 0.5772234555145531\n",
                  "Round 2 beta_f1: 0.5754072620427306\n",
                  "Round 3 beta_f1: 0.5810758784312391\n",
                  "Round 4 beta_f1: 0.5783983145866527\n",
                  "average beta f1-score after kfold: 0.5784596908490335\n",
                  "Testing data:\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           1       0.35      0.39      0.37     13140\n",
                  "           2       0.92      0.91      0.92   1191687\n",
                  "           3       0.70      0.70      0.70    252647\n",
                  "           4       0.33      0.34      0.33     38727\n",
                  "\n",
                  "    accuracy                           0.86   1496201\n",
                  "   macro avg       0.57      0.59      0.58   1496201\n",
                  "weighted avg       0.86      0.86      0.86   1496201\n",
                  "\n",
                  "beta f1 for level [1]: 0.3597785977859779, pr: 0.3525785905074995, rc: 0.3917808219178082\n",
                  "beta f1 for level [2]: 0.9163375402627796, pr: 0.9186047786382239, rc: 0.9140814660225378\n",
                  "beta f1 for level [3]: 0.7008308667285041, pr: 0.6974123604665747, rc: 0.7042830510554252\n",
                  "beta f1 for level [4]: 0.33822032901566323, pr: 0.32545208512732193, rc: 0.3415704805432902\n",
                  "beta f1-score: 0.8600957356572978\n"
               ]
            }
         ],
         "source": [
            "dt = DecisionTreeClassifier()\n",
            "cross_valid(x_train_valid, y_train_valid, dt, verbose=True, balance_cls=False, equal_weighted_f1=True)\n",
            "test(dt, x_test, y_test)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Decision tree with balance dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Validation data\n",
                  "After under sampling:\n",
                  "Length of training data: 167888, and its distribution among each severity Counter({1: 41972, 2: 41972, 3: 41972, 4: 41972})\n",
                  "Round 0 beta_f1: 0.4256565240979158\n",
                  "After under sampling:\n",
                  "Length of training data: 168796, and its distribution among each severity Counter({1: 42199, 2: 42199, 3: 42199, 4: 42199})\n",
                  "Round 1 beta_f1: 0.4284265706449773\n",
                  "After under sampling:\n",
                  "Length of training data: 168524, and its distribution among each severity Counter({1: 42131, 2: 42131, 3: 42131, 4: 42131})\n",
                  "Round 2 beta_f1: 0.4270808646509177\n",
                  "After under sampling:\n",
                  "Length of training data: 168052, and its distribution among each severity Counter({1: 42013, 2: 42013, 3: 42013, 4: 42013})\n",
                  "Round 3 beta_f1: 0.42556061318497174\n",
                  "After under sampling:\n",
                  "Length of training data: 167684, and its distribution among each severity Counter({1: 41921, 2: 41921, 3: 41921, 4: 41921})\n",
                  "Round 4 beta_f1: 0.42801343045078577\n",
                  "average beta f1-score after kfold: 0.42694760060591364\n",
                  "Testing data:\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           1       0.09      0.84      0.17     13140\n",
                  "           2       0.93      0.59      0.72   1191687\n",
                  "           3       0.45      0.66      0.54    252647\n",
                  "           4       0.11      0.72      0.19     38727\n",
                  "\n",
                  "    accuracy                           0.61   1496201\n",
                  "   macro avg       0.40      0.70      0.40   1496201\n",
                  "weighted avg       0.82      0.61      0.67   1496201\n",
                  "\n",
                  "beta f1 for level [1]: 0.11282487496925471, pr: 0.09275814129839491, rc: 0.8378234398782344\n",
                  "beta f1 for level [2]: 0.7226653491957653, pr: 0.9328280160434479, rc: 0.5897882581583923\n",
                  "beta f1 for level [3]: 0.5366754981996849, pr: 0.4516936042234627, rc: 0.6610448570535173\n",
                  "beta f1 for level [4]: 0.3389080850190359, pr: 0.10906817449020517, rc: 0.7162444805949337\n",
                  "beta f1-score: 0.6759705205693205\n"
               ]
            }
         ],
         "source": [
            "dt = DecisionTreeClassifier()\n",
            "cross_valid(x_train_valid, y_train_valid, dt, verbose=True, balance_cls=True, equal_weighted_f1=True)\n",
            "test(dt, x_test, y_test)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### OneVsRestClassifier with decision tree as base model"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "without balance dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Validation data\n",
                  "Round 0 beta_f1: 0.6176041931450036\n",
                  "Round 1 beta_f1: 0.6169444525288569\n",
                  "Round 2 beta_f1: 0.6157151080500922\n",
                  "Round 3 beta_f1: 0.6205029830756664\n",
                  "Round 4 beta_f1: 0.6157815213023662\n",
                  "average beta f1-score after kfold: 0.6173096516203971\n",
                  "Testing data:\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           1       0.68      0.29      0.41     13140\n",
                  "           2       0.95      0.87      0.90   1191687\n",
                  "           3       0.70      0.70      0.70    252647\n",
                  "           4       0.13      0.49      0.20     38727\n",
                  "\n",
                  "    accuracy                           0.82   1496201\n",
                  "   macro avg       0.62      0.59      0.56   1496201\n",
                  "weighted avg       0.88      0.82      0.85   1496201\n",
                  "\n",
                  "beta f1 for level [1]: 0.5400716364450413, pr: 0.683306779961055, rc: 0.2937595129375951\n",
                  "beta f1 for level [2]: 0.9045621401744798, pr: 0.9451181486839145, rc: 0.8673435222503896\n",
                  "beta f1 for level [3]: 0.7017144036908515, pr: 0.7038970866439652, rc: 0.6995452152608185\n",
                  "beta f1 for level [4]: 0.31432770412930205, pr: 0.12963762898968081, rc: 0.48821235830299275\n",
                  "beta f1-score: 0.8518310657378863\n"
               ]
            }
         ],
         "source": [
            "clf = OneVsRestClassifier(DecisionTreeClassifier())\n",
            "cross_valid(x_train_valid, y_train_valid, clf, verbose=True, balance_cls=False, equal_weighted_f1=True)\n",
            "test(clf, x_test, y_test)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "with balance dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Validation data\n",
                  "After under sampling:\n",
                  "Length of training data: 167888, and its distribution among each severity Counter({1: 41972, 2: 41972, 3: 41972, 4: 41972})\n",
                  "Round 0 beta_f1: 0.39169999023593943\n",
                  "After under sampling:\n",
                  "Length of training data: 168796, and its distribution among each severity Counter({1: 42199, 2: 42199, 3: 42199, 4: 42199})\n",
                  "Round 1 beta_f1: 0.3923815858009088\n",
                  "After under sampling:\n",
                  "Length of training data: 168524, and its distribution among each severity Counter({1: 42131, 2: 42131, 3: 42131, 4: 42131})\n",
                  "Round 2 beta_f1: 0.3929587762643762\n",
                  "After under sampling:\n",
                  "Length of training data: 168052, and its distribution among each severity Counter({1: 42013, 2: 42013, 3: 42013, 4: 42013})\n",
                  "Round 3 beta_f1: 0.39395352954115154\n",
                  "After under sampling:\n",
                  "Length of training data: 167684, and its distribution among each severity Counter({1: 41921, 2: 41921, 3: 41921, 4: 41921})\n",
                  "Round 4 beta_f1: 0.39329184233732095\n",
                  "average beta f1-score after kfold: 0.39285714483593936\n",
                  "Testing data:\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           1       0.15      0.76      0.25     13140\n",
                  "           2       0.96      0.45      0.61   1191687\n",
                  "           3       0.46      0.63      0.54    252647\n",
                  "           4       0.06      0.87      0.12     38727\n",
                  "\n",
                  "    accuracy                           0.49   1496201\n",
                  "   macro avg       0.41      0.68      0.38   1496201\n",
                  "weighted avg       0.84      0.49      0.58   1496201\n",
                  "\n",
                  "beta f1 for level [1]: 0.17846372565914181, pr: 0.14983948998507934, rc: 0.7566210045662101\n",
                  "beta f1 for level [2]: 0.6111752794848597, pr: 0.9581542872502464, rc: 0.44868996640896475\n",
                  "beta f1 for level [3]: 0.5350049652432969, pr: 0.4642544185247615, rc: 0.6311968873566676\n",
                  "beta f1 for level [4]: 0.24592695375220833, pr: 0.06360743739861405, rc: 0.8677150308570248\n",
                  "beta f1-score: 0.5850591339201218\n"
               ]
            }
         ],
         "source": [
            "clf = OneVsRestClassifier(DecisionTreeClassifier())\n",
            "cross_valid(x_train_valid, y_train_valid, clf, verbose=True, balance_cls=True, equal_weighted_f1=True)\n",
            "test(clf, x_test, y_test)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### OneVsRestClassifier with Random Forest as base model"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Without balance"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Validation data\n",
                  "Round 0 beta_f1: 0.6433005435587963\n",
                  "Round 1 beta_f1: 0.6412018500555894\n",
                  "Round 2 beta_f1: 0.6431255012023854\n",
                  "Round 3 beta_f1: 0.6447565281213\n",
                  "Round 4 beta_f1: 0.6448057622574268\n",
                  "average beta f1-score after kfold: 0.6434380370390996\n",
                  "Testing data:\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           1       0.87      0.26      0.40     13140\n",
                  "           2       0.91      0.97      0.94   1191687\n",
                  "           3       0.84      0.69      0.76    252647\n",
                  "           4       0.55      0.25      0.35     38727\n",
                  "\n",
                  "    accuracy                           0.90   1496201\n",
                  "   macro avg       0.79      0.54      0.61   1496201\n",
                  "weighted avg       0.89      0.90      0.89   1496201\n",
                  "\n",
                  "beta f1 for level [1]: 0.5939472961844633, pr: 0.86528367908023, rc: 0.2634703196347032\n",
                  "beta f1 for level [2]: 0.9382141328529187, pr: 0.9106120808188983, rc: 0.967541812573268\n",
                  "beta f1 for level [3]: 0.7579423373613712, pr: 0.8388326945429047, rc: 0.6912807197393992\n",
                  "beta f1 for level [4]: 0.2825786130748699, pr: 0.5482167930356642, rc: 0.2520463759134454\n",
                  "beta f1-score: 0.8877800058046003\n"
               ]
            }
         ],
         "source": [
            "clf = OneVsRestClassifier(RandomForestClassifier())\n",
            "cross_valid(x_train_valid, y_train_valid, clf, verbose=True, balance_cls=False, equal_weighted_f1=True)\n",
            "test(clf, x_test, y_test)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Balance"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Validation data\n",
                  "After under sampling:\n",
                  "Length of training data: 167888, and its distribution among each severity Counter({1: 41972, 2: 41972, 3: 41972, 4: 41972})\n",
                  "Round 0 beta_f1: 0.46595173248051747\n",
                  "After under sampling:\n",
                  "Length of training data: 168796, and its distribution among each severity Counter({1: 42199, 2: 42199, 3: 42199, 4: 42199})\n",
                  "Round 1 beta_f1: 0.4665954173794879\n",
                  "After under sampling:\n",
                  "Length of training data: 168524, and its distribution among each severity Counter({1: 42131, 2: 42131, 3: 42131, 4: 42131})\n",
                  "Round 2 beta_f1: 0.4655583321854403\n",
                  "After under sampling:\n",
                  "Length of training data: 168052, and its distribution among each severity Counter({1: 42013, 2: 42013, 3: 42013, 4: 42013})\n",
                  "Round 3 beta_f1: 0.46462977550085216\n",
                  "After under sampling:\n",
                  "Length of training data: 167684, and its distribution among each severity Counter({1: 41921, 2: 41921, 3: 41921, 4: 41921})\n",
                  "Round 4 beta_f1: 0.4637156881971976\n",
                  "average beta f1-score after kfold: 0.4652901891486991\n",
                  "Testing data:\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           1       0.10      0.93      0.18     13140\n",
                  "           2       0.97      0.59      0.73   1191687\n",
                  "           3       0.53      0.76      0.62    252647\n",
                  "           4       0.12      0.87      0.20     38727\n",
                  "\n",
                  "    accuracy                           0.63   1496201\n",
                  "   macro avg       0.43      0.79      0.44   1496201\n",
                  "weighted avg       0.86      0.63      0.69   1496201\n",
                  "\n",
                  "beta f1 for level [1]: 0.12307846678707604, pr: 0.10112952428064968, rc: 0.9334855403348554\n",
                  "beta f1 for level [2]: 0.7308793537265986, pr: 0.9689796676363264, rc: 0.5867111078664112\n",
                  "beta f1 for level [3]: 0.6231202625907285, pr: 0.5283668994998127, rc: 0.7592846936634909\n",
                  "beta f1 for level [4]: 0.3774629601344128, pr: 0.11577812379430083, rc: 0.867844139747463\n",
                  "beta f1-score: 0.6981977344607152\n"
               ]
            }
         ],
         "source": [
            "clf = OneVsRestClassifier(RandomForestClassifier())\n",
            "cross_valid(x_train_valid, y_train_valid, clf, verbose=True, balance_cls=True, equal_weighted_f1=True)\n",
            "test(clf, x_test, y_test)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.6"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
