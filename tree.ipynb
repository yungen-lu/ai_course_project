{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "import pandas as pd\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.metrics import classification_report\n",
            "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\n",
            "from sklearn.tree import DecisionTreeClassifier\n",
            "from collections import Counter\n",
            "from sklearn.svm import LinearSVC\n",
            "from sklearn.pipeline import make_pipeline\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from imblearn.under_sampling import RandomUnderSampler\n",
            "import matplotlib.pyplot as plt\n",
            "rus = RandomUnderSampler(random_state=42)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "ori_data = pd.read_csv('./data/v2-4.csv', index_col=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "numerical_features = [\n",
            "    'Distance(mi)', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)',\n",
            "    'Wind_Speed(mph)', 'elapsed_time', 'Start_Lat', 'Start_Lng'\n",
            "]\n",
            "\n",
            "categorical_features = [f for f in list(ori_data.columns) if (f not in numerical_features)]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "# X_b = ori_data.drop(info_cols, axis=1)\n",
            "X = ori_data.drop(['Severity'], axis=1)\n",
            "y = ori_data['Severity']"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "def custom_scoring(y_true, y_pred, verbose=False):\n",
            "    report = classification_report(y_true, y_pred, output_dict=True)\n",
            "    weighted_beta_f1 = 0\n",
            "    beta_weights = {\n",
            "        '1': 0.5,\n",
            "        '2': 1,\n",
            "        '3': 1,\n",
            "        '4': 2,\n",
            "    }\n",
            "    # print(report)\n",
            "    total_data_count = report['weighted avg']['support']\n",
            "    for cl in range(1, 5):\n",
            "        pr = report[str(cl)]['precision']\n",
            "        rc = report[str(cl)]['recall']\n",
            "        beta = beta_weights[str(cl)]\n",
            "        beta_f1 = ((1+beta**2)*pr*rc)/(pr*(beta**2) + rc)\n",
            "        if verbose: \n",
            "            print(f'beta f1 for level [{cl}]: {beta_f1}, pr: {pr}, rc: {rc}')\n",
            "\n",
            "        support_proportion = report[str(cl)]['support'] / total_data_count\n",
            "        weighted_beta_f1 += beta_f1 * support_proportion\n",
            "\n",
            "    if verbose:\n",
            "        print(f\"macro avg for f1: {weighted_beta_f1}\")\n",
            "    return weighted_beta_f1"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.model_selection import KFold\n",
            "from sklearn.metrics import precision_recall_curve, auc\n",
            "\n",
            "def cross_valid(X, y, estimator, cv=5, verbose=False):\n",
            "    total_f1 = 0\n",
            "    X.reset_index()\n",
            "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
            "    print('Validation data')\n",
            "    for i, (train_index, valid_index) in enumerate(kf.split(X)):\n",
            "        x_train, x_valid = X.iloc[train_index], X.iloc[valid_index]\n",
            "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
            "        \n",
            "        x_train_balan, y_train_balan = rus.fit_resample(x_train, y_train)\n",
            "        if verbose:\n",
            "            print('After under sampling:')\n",
            "            print(f'Length of training data: {len(x_train_balan)}, and its distribution among each severity {Counter(y_train_balan)}')\n",
            "\n",
            "        estimator.fit(x_train_balan, y_train_balan)\n",
            "        y_valid_pred = estimator.predict(x_valid)\n",
            "        beta_f1 = custom_scoring(y_valid, y_valid_pred, verbose=False)\n",
            "        print(f'Round {i} beta_f1: {beta_f1}')\n",
            "        total_f1 += beta_f1\n",
            "        \n",
            "    avg_betaf1 = total_f1 / cv\n",
            "    print(f'average beta f1-score after kfold: {avg_betaf1}')\n",
            "\n",
            "\n",
            "def test(estimator, x_test, y_test):\n",
            "    print('Testing data:')\n",
            "    y_test_pred = estimator.predict(x_test)\n",
            "    print(classification_report(y_test, y_test_pred))\n",
            "    beta_f1 = custom_scoring(y_test, y_test_pred, verbose=True)\n",
            "    print(f'beta f1-score: {beta_f1}')\n",
            "        \n",
            "def auc_pr(estimator, x_test, y_test):\n",
            "    y_scores = estimator.predict_proba(x_test)[:, 1]\n",
            "    precision = dict()\n",
            "    recall = dict()\n",
            "    n_classes = 4\n",
            "    for i in range(n_classes):\n",
            "        precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_scores[:, i])\n",
            "        plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
            "        \n",
            "    plt.xlabel(\"recall\")\n",
            "    plt.ylabel(\"precision\")\n",
            "    plt.legend(loc=\"best\")\n",
            "    plt.title(\"precision vs. recall curve\")\n",
            "    plt.show()\n",
            "        "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Model"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "x_train_valid, x_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 23,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Validation data\n",
                  "After under sampling:\n",
                  "Length of training data: 168316, and its distribution among each severity Counter({1: 42079, 2: 42079, 3: 42079, 4: 42079})\n",
                  "Round 0 beta_f1: 0.6743087649416701\n",
                  "After under sampling:\n",
                  "Length of training data: 167940, and its distribution among each severity Counter({1: 41985, 2: 41985, 3: 41985, 4: 41985})\n",
                  "Round 1 beta_f1: 0.6756818602948657\n",
                  "After under sampling:\n",
                  "Length of training data: 167924, and its distribution among each severity Counter({1: 41981, 2: 41981, 3: 41981, 4: 41981})\n",
                  "Round 2 beta_f1: 0.6766462053608783\n",
                  "After under sampling:\n",
                  "Length of training data: 168480, and its distribution among each severity Counter({1: 42120, 2: 42120, 3: 42120, 4: 42120})\n",
                  "Round 3 beta_f1: 0.6718258381337472\n",
                  "After under sampling:\n",
                  "Length of training data: 168284, and its distribution among each severity Counter({1: 42071, 2: 42071, 3: 42071, 4: 42071})\n",
                  "Round 4 beta_f1: 0.6744575353594671\n",
                  "average beta f1-score after kfold: 0.6745840408181257\n",
                  "Testing data:\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           1       0.09      0.83      0.16     13140\n",
                  "           2       0.93      0.59      0.72   1191687\n",
                  "           3       0.45      0.67      0.54    252647\n",
                  "           4       0.11      0.71      0.19     38727\n",
                  "\n",
                  "    accuracy                           0.61   1496201\n",
                  "   macro avg       0.40      0.70      0.40   1496201\n",
                  "weighted avg       0.82      0.61      0.67   1496201\n",
                  "\n",
                  "beta f1 for level [1]: 0.10847136189060029, pr: 0.08910462628802848, rc: 0.8305175038051751\n",
                  "beta f1 for level [2]: 0.7198494787169608, pr: 0.9331616410821156, rc: 0.5859147578181183\n",
                  "beta f1 for level [3]: 0.5398404078182237, pr: 0.4532659398566992, rc: 0.6672946838870044\n",
                  "beta f1 for level [4]: 0.3364410016354431, pr: 0.10839933108257344, rc: 0.7096857489606734\n",
                  "macro avg for f1: 0.674160082517929\n",
                  "beta f1-score: 0.674160082517929\n"
               ]
            }
         ],
         "source": [
            "x_train_valid, x_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
            "dt = DecisionTreeClassifier()\n",
            "cross_valid(x_train_valid, y_train_valid, dt, verbose=True)\n",
            "test(dt, x_test, y_test)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Validation data\n",
                  "After under sampling:\n",
                  "Length of training data: 168316, and its distribution among each severity Counter({1: 42079, 2: 42079, 3: 42079, 4: 42079})\n",
                  "Round 0 beta_f1: 0.5823601850660766\n",
                  "After under sampling:\n",
                  "Length of training data: 167940, and its distribution among each severity Counter({1: 41985, 2: 41985, 3: 41985, 4: 41985})\n",
                  "Round 1 beta_f1: 0.5850641210123708\n",
                  "After under sampling:\n",
                  "Length of training data: 167924, and its distribution among each severity Counter({1: 41981, 2: 41981, 3: 41981, 4: 41981})\n",
                  "Round 2 beta_f1: 0.5863385157724416\n",
                  "After under sampling:\n",
                  "Length of training data: 168480, and its distribution among each severity Counter({1: 42120, 2: 42120, 3: 42120, 4: 42120})\n",
                  "Round 3 beta_f1: 0.5808432141821133\n",
                  "After under sampling:\n",
                  "Length of training data: 168284, and its distribution among each severity Counter({1: 42071, 2: 42071, 3: 42071, 4: 42071})\n",
                  "Round 4 beta_f1: 0.5844132016657172\n",
                  "average beta f1-score after kfold: 0.5838038475397439\n",
                  "Testing data:\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           1       0.15      0.76      0.25     13140\n",
                  "           2       0.96      0.45      0.61   1191687\n",
                  "           3       0.46      0.63      0.54    252647\n",
                  "           4       0.06      0.87      0.12     38727\n",
                  "\n",
                  "    accuracy                           0.49   1496201\n",
                  "   macro avg       0.41      0.68      0.38   1496201\n",
                  "weighted avg       0.84      0.49      0.58   1496201\n",
                  "\n",
                  "beta f1 for level [1]: 0.17657325257350853, pr: 0.14817963518129074, rc: 0.7560882800608828\n",
                  "beta f1 for level [2]: 0.6099962694509228, pr: 0.9586544254511775, rc: 0.44731124867519745\n",
                  "beta f1 for level [3]: 0.5356248783532555, pr: 0.464881852152816, rc: 0.6317628944733166\n",
                  "beta f1 for level [4]: 0.24464856370020277, pr: 0.0632371151145407, rc: 0.865055387713998\n",
                  "macro avg for f1: 0.584175067694588\n",
                  "beta f1-score: 0.584175067694588\n"
               ]
            }
         ],
         "source": [
            "from sklearn.multiclass import OneVsRestClassifier\n",
            "clf = OneVsRestClassifier(DecisionTreeClassifier())\n",
            "\n",
            "cross_valid(x_train_valid, y_train_valid, clf, verbose=True)\n",
            "test(clf, x_test, y_test)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Testing data:\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           1       0.70      0.31      0.43     13140\n",
                  "           2       0.95      0.87      0.91   1191687\n",
                  "           3       0.71      0.71      0.71    252647\n",
                  "           4       0.13      0.49      0.21     38727\n",
                  "\n",
                  "    accuracy                           0.83   1496201\n",
                  "   macro avg       0.62      0.59      0.56   1496201\n",
                  "weighted avg       0.88      0.83      0.85   1496201\n",
                  "\n",
                  "beta f1 for level [1]: 0.5571057575422699, pr: 0.6996877168632893, rc: 0.3069254185692542\n",
                  "beta f1 for level [2]: 0.9073552951967069, pr: 0.9461156329243056, rc: 0.8716458264628212\n",
                  "beta f1 for level [3]: 0.712954568448868, pr: 0.714680030227101, rc: 0.7112374182159298\n",
                  "beta f1 for level [4]: 0.31863647572687626, pr: 0.13368150284511654, rc: 0.4871278436233119\n",
                  "macro avg for f1: 0.8562148715122896\n",
                  "beta f1-score: 0.8562148715122896\n"
               ]
            }
         ],
         "source": [
            "clf = OneVsRestClassifier(DecisionTreeClassifier()).fit(x_train_valid, y_train_valid)\n",
            "test(clf, x_test, y_test)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.6"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}