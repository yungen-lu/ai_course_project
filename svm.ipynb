{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data = pd.read_csv('./data/v2-4.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ori_data.drop(['Severity'], axis=1)\n",
    "y = ori_data['Severity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scoring(y_true, y_pred, verbose=False, equal_weighted_f1=False):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    weighted_beta_f1 = 0\n",
    "    beta_weights = {\n",
    "        '1': 0.5,\n",
    "        '2': 1,\n",
    "        '3': 1,\n",
    "        '4': 2,\n",
    "    }\n",
    "    total_data_count = report['weighted avg']['support']\n",
    "    for cl in range(1, 5):\n",
    "        pr = report[str(cl)]['precision']\n",
    "        rc = report[str(cl)]['recall']\n",
    "        beta = beta_weights[str(cl)]\n",
    "        beta_f1 = ((1+beta**2)*pr*rc)/(pr*(beta**2) + rc)\n",
    "        if verbose: \n",
    "            print(f'beta f1 for level [{cl}]: {beta_f1}, pr: {pr}, rc: {rc}')\n",
    "\n",
    "        if not equal_weighted_f1:\n",
    "            support_proportion = report[str(cl)]['support'] / total_data_count\n",
    "            weighted_beta_f1 += beta_f1 * support_proportion\n",
    "        else:\n",
    "            weighted_beta_f1 += beta_f1*0.25\n",
    "\n",
    "    if verbose and equal_weighted_f1:\n",
    "        print(f\"macro avg for f1: {weighted_beta_f1}\")\n",
    "    return weighted_beta_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_valid(X, y, estimator, cv=5, verbose=False, balance_cls=False, equal_weighted_f1=False):\n",
    "    total_f1 = 0\n",
    "    X.reset_index()\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    print('Validation data')\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(X)):\n",
    "        x_train, x_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        if balance_cls:\n",
    "            x_train, y_train = rus.fit_resample(x_train, y_train)\n",
    "            if verbose:\n",
    "                print('After under sampling:')\n",
    "                print(f'Length of training data: {len(x_train)}, and its distribution among each severity {Counter(y_train)}')\n",
    "\n",
    "        estimator.fit(x_train, y_train)\n",
    "        y_valid_pred = estimator.predict(x_valid)\n",
    "        beta_f1 = custom_scoring(y_valid, y_valid_pred, verbose=False, equal_weighted_f1=equal_weighted_f1)\n",
    "        print(f'Round {i} beta_f1: {beta_f1}')\n",
    "        total_f1 += beta_f1\n",
    "        \n",
    "    avg_betaf1 = total_f1 / cv\n",
    "    print(f'average beta f1-score after kfold: {avg_betaf1}')\n",
    "\n",
    "\n",
    "def test(estimator, x_test, y_test):\n",
    "    print('Testing data:')\n",
    "    y_test_pred = estimator.predict(x_test)\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    beta_f1 = custom_scoring(y_test, y_test_pred, verbose=True)\n",
    "    print(f'beta f1-score: {beta_f1}')\n",
    "        \n",
    "def auc_pr(estimator, x_test, y_test):\n",
    "    y_scores = estimator.predict_proba(x_test)[:, 1]\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    n_classes = 4\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_scores[:, i])\n",
    "        plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
    "        \n",
    "    plt.xlabel(\"recall\")\n",
    "    plt.ylabel(\"precision\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"precision vs. recall curve\")\n",
    "    plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_valid, x_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ori_data.drop(['Severity'], axis=1)\n",
    "y = ori_data['Severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yungen/Library/Caches/pypoetry/virtualenvs/traffic-accident-predict-4yLnMnDS-py3.9/lib/python3.9/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/yungen/Library/Caches/pypoetry/virtualenvs/traffic-accident-predict-4yLnMnDS-py3.9/lib/python3.9/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yungen/Library/Caches/pypoetry/virtualenvs/traffic-accident-predict-4yLnMnDS-py3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yungen/Library/Caches/pypoetry/virtualenvs/traffic-accident-predict-4yLnMnDS-py3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yungen/Library/Caches/pypoetry/virtualenvs/traffic-accident-predict-4yLnMnDS-py3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00     13140\n",
      "           2       0.81      0.15      0.25   1191687\n",
      "           3       0.17      0.86      0.29    252647\n",
      "           4       0.12      0.00      0.00     38727\n",
      "\n",
      "    accuracy                           0.27   1496201\n",
      "   macro avg       0.28      0.25      0.13   1496201\n",
      "weighted avg       0.68      0.27      0.25   1496201\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yungen/Library/Caches/pypoetry/virtualenvs/traffic-accident-predict-4yLnMnDS-py3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yungen/Library/Caches/pypoetry/virtualenvs/traffic-accident-predict-4yLnMnDS-py3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yungen/Library/Caches/pypoetry/virtualenvs/traffic-accident-predict-4yLnMnDS-py3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lin_clf \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mLinearSVC()\n\u001b[1;32m      2\u001b[0m lin_clf\u001b[38;5;241m.\u001b[39mfit(x_train_valid, y_train_valid)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlin_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(estimator, x_test, y_test)\u001b[0m\n\u001b[1;32m     28\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_test_pred))\n\u001b[0;32m---> 30\u001b[0m beta_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta f1-score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbeta_f1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m, in \u001b[0;36mcustom_scoring\u001b[0;34m(y_true, y_pred, verbose, equal_weighted_f1)\u001b[0m\n\u001b[1;32m     13\u001b[0m rc \u001b[38;5;241m=\u001b[39m report[\u001b[38;5;28mstr\u001b[39m(cl)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m beta \u001b[38;5;241m=\u001b[39m beta_weights[\u001b[38;5;28mstr\u001b[39m(cl)]\n\u001b[0;32m---> 15\u001b[0m beta_f1 \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpr\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpr\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose: \n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta f1 for level [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbeta_f1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, pr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, rc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(x_train_valid, y_train_valid)\n",
    "test(lin_clf, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-accident-predict-4yLnMnDS-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
